<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
-->
<configuration>
        <property>
                <name>ha.zookeeper.quorum2</name>
                <value>node118,node119,node120</value>
        </property>
	<property>
        	<name>hbase.zookeeper.quorum</name>
        	<value>node118:2181,node119:2181,node120:2181</value>
	</property>
	<property>
	        <name>hbase.zookeeper.property.dataDir</name>
	        <value>/opt/hbase-2.3.5/zkdata</value>
	</property>
	<property>
	        <name>hbase.rootdir</name>
	        <value>hdfs://hr-hadoop/hbase</value>
	</property>

  <!--
    The following properties are set for running HBase as a single process on a
    developer workstation. With this configuration, HBase is running in
    "stand-alone" mode and without a distributed file system. In this mode, and
    without further configuration, HBase and ZooKeeper data are stored on the
    local filesystem, in a path under the value configured for `hbase.tmp.dir`.
    This value is overridden from its default value of `/tmp` because many
    systems clean `/tmp` on a regular basis. Instead, it points to a path within
    this HBase installation directory.

    Running against the `LocalFileSystem`, as opposed to a distributed
    filesystem, runs the risk of data integrity issues and data loss. Normally
    HBase will refuse to run in such an environment. Setting
    `hbase.unsafe.stream.capability.enforce` to `false` overrides this behavior,
    permitting operation. This configuration is for the developer workstation
    only and __should not be used in production!__

    See also https://hbase.apache.org/book.html#standalone_dist
  -->


<!--禁用major_compaction默认是7天 0为禁用-->
<property>
        <name>hbase.hregion.majorcompaction</name>
        <value>0</value>
</property>
<property>
        <name>hbase.master.distributed.log.splitting</name>
        <value>false</value>
</property>
<property>
        <name>phoenix.schema.isNamespaceMappingEnabled</name>
        <value>true</value>
</property>

<!-- compact参数调优 -->
<property>
        <name>hbase.hstore.compaction.min</name>
        <value>6</value>
</property>

<property>
        <name>hbase.hstore.compaction.max</name>
        <value>18</value>
</property>

<property>
        <name>hbase.regionserver.thread.compaction.small</name>
        <value>3</value>
</property>

<property>
        <name>hbase.regionserver.thread.compaction.large</name>
        <value>3</value>
</property>
<property>
        <name>hbase.hstore.blockingStoreFiles</name>
        <value>100</value>
</property>


<property>
        <name>phoenix.schema.mapSystemTablesToNamespace</name>
        <value>true</value>
</property>

<!--Hbase 通过协处理器来进行分布式聚合-->
<property>
        <name>hbase.coprocessor.region.classes</name>
        <value>org.apache.hadoop.hbase.coprocessor.AggregateImplementation</value>
</property>


<!--配置可变索引-->
<!--
          <property>
        <name>hbase.regionserver.wal.codec</name>
        <value>org.apache.hadoop.hbase.regionserver.wal.IndexedWALEditCodec</value>
</property>
-->
<!--提升 RPC处理线程数量-->
<property>
        <name>hbase.regionserver.handler.count</name>
        <value>120</value>
</property>
<property>
         <name>hbase.ipc.server.callqueue.handler.factor</name>
         <value>0.5</value>
         <!-- 处理用户线程比例 80*0.2=16 16个队列处理用户的请求-->
 </property>
<property>
         <name>hbase.ipc.server.callqueue.read.ratio</name>
         <value>0.5</value>
         <!-- 用户读写请求的处理队列比例 16*0.5=8 8个处理读请求、8个处理写请求-->
</property>
<property>
         <name>hbase.ipc.server.callqueue.scan.ratio</name>
         <value>0.5</value>
         <!-- scan和get请求处理比例 8*0.5=4 4个线程处理scan，4个线程处理get -->
 </property>
<!--自动分裂大小-->
  <property>
    <name>hbase.hregion.max.filesize</name>
    <value>10737418240</value>
    <description>
    Maximum HStoreFile size. If any one of a column families' HStoreFiles has
    grown to exceed this value, the hosting HRegion is split in two.</description>
  </property>
   <!--<property>
                <name>hbase.bucketcache.ioengine</name>
        <value>file:/offheap/bucketcache</value>
    </property>-->
    <property>
        <name>hbase.bucketcache.ioengine</name>
        <value>offheap</value>
    </property>
    <property>
        <name>hbase.bucketcache.percentage.in.combinedcache</name>
        <value>0.90</value>
    </property>
    <property>
        <name>hfile.block.cache.size</name>
        <value>0.2</value>
    </property>
    <property>
        <name>hbase.bucketcache.size</name>
        <value>4096</value>
    </property>
    <property>
        <name>zookeeper.session.timeout</name>
        <value>300000</value>
    </property>
    <property>
        <name>hbase.replication</name>
        <value>true</value>
    </property>
    <property>
        <name>hbase.hstore.min.locality.to.skip.major.compact</name>
        <value>0.8</value>
    </property>
	<property>
	         <name>dfs.client.read.shortcircuit</name>
	         <value>true</value>
	         <!-- Hdfs短路读取文件功能开启 -->
	 </property>
	 <property>
	         <name>dfs.domain.socket.path</name>
	         <value>/home/hr/hdfs/socket</value>
	 </property>
	 <property>
        	 <name>dfs.client.read.shortcircuit.buffer.size</name>
	         <value>131072</value>
        	 <!-- Hbase的DFSClient读文件的BUFFER大小 -->
	 </property>
	<property>
    		<name>hbase.cluster.distributed</name>
    		<value>true</value>
  	</property>
  	<property>
  		<name>hbase.tmp.dir</name>
    		<value>/home/hr/hbase</value>
  	</property>
  	<property>
    		<name>hbase.unsafe.stream.capability.enforce</name>
    		<value>false</value>
  	</property>

    <property>
       <name>phoenix.mutate.maxSize</name>
       <value>15000000</value>
    </property>
    <property>
       <name>phoenix.mutate.batchSize</name>
       <value>200000</value>
    </property>
    <property>
       <name>phoenix.mutate.maxSizeBytes</name>
       <value>1048576000</value>
    </property>
</configuration>
